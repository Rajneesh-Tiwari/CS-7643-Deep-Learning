{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46537662",
   "metadata": {},
   "source": [
    "### Classification notebook for Kaggle RSNA competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d241113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:40.770422Z",
     "iopub.status.busy": "2022-10-21T04:46:40.768650Z",
     "iopub.status.idle": "2022-10-21T04:46:46.027848Z",
     "shell.execute_reply": "2022-10-21T04:46:46.026647Z"
    },
    "id": "_b9cHesklRKW",
    "outputId": "0251b11b-0475-4dbb-dd52-7b75ec6d27e9",
    "papermill": {
     "duration": 5.275668,
     "end_time": "2022-10-21T04:46:46.030655",
     "exception": false,
     "start_time": "2022-10-21T04:46:40.754987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold,StratifiedGroupKFold\n",
    "import warnings\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "from requests import get\n",
    "import multiprocessing\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import timm\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2,torchvision\n",
    "from ipyexperiments.ipyexperiments import IPyExperimentsPytorch\n",
    "from timm.optim.optim_factory import create_optimizer_v2\n",
    "from timm import utils\n",
    "from fastprogress.fastprogress import format_time\n",
    "from fastai.vision.all import *\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.feature import canny\n",
    "from skimage.filters import sobel\n",
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "from skimage.draw import polygon\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "class CFG:\n",
    "    seed = 46\n",
    "    n_splits = 4\n",
    "    SZ = (1536, 960)\n",
    "    debug = False\n",
    "    BS = 16\n",
    "    EP = 12\n",
    "    MODEL = 'tf_efficientnet_b4_ns'\n",
    "    LR = 4e-04\n",
    "    WD = 1e-08\n",
    "    debug = False\n",
    "\n",
    "random.seed(CFG.seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(CFG.seed)\n",
    "np.random.seed(CFG.seed)\n",
    "plt.rcParams[\"font.size\"] = 13\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe7694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:46.053836Z",
     "iopub.status.busy": "2022-10-21T04:46:46.053171Z",
     "iopub.status.idle": "2022-10-21T04:46:46.061921Z",
     "shell.execute_reply": "2022-10-21T04:46:46.060953Z"
    },
    "papermill": {
     "duration": 0.022786,
     "end_time": "2022-10-21T04:46:46.064147",
     "exception": false,
     "start_time": "2022-10-21T04:46:46.041361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a4371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:46.086954Z",
     "iopub.status.busy": "2022-10-21T04:46:46.086674Z",
     "iopub.status.idle": "2022-10-21T04:46:46.149851Z",
     "shell.execute_reply": "2022-10-21T04:46:46.148778Z"
    },
    "id": "PD4IsNvglQYA",
    "papermill": {
     "duration": 0.077084,
     "end_time": "2022-10-21T04:46:46.152797",
     "exception": false,
     "start_time": "2022-10-21T04:46:46.075713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = '///mnt/c/Personal/Competitions/Kaggle/rsna'\n",
    "image_dir = f'{root_dir}/data/8bit'\n",
    "DIR = '///mnt/c/Personal/Competitions/Kaggle/rsna/data/'\n",
    "submit = pd.read_csv(os.path.join(DIR,'sample_submission.csv'))\n",
    "train = pd.read_csv(os.path.join(DIR,'Train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DIR,'Test.csv'))\n",
    "\n",
    "if CFG.debug:\n",
    "    train = train.sample(frac=0.01).reset_index(drop=True)\n",
    "    \n",
    "VERSION = \"Baseline_LargerSZ_MoreAugs_PreProc_LargerModel\"\n",
    "MODEL_FOLDER = Path(f\"{root_dir}/runs/{VERSION}/\")\n",
    "os.makedirs(MODEL_FOLDER,exist_ok=True)\n",
    "KERNEL_TYPE = f\"{CFG.MODEL}_{CFG.SZ[0]}_{CFG.SZ[1]}_bs{CFG.BS}_ep{CFG.EP}_lr{str(CFG.LR).replace('-','')}_wd{str(CFG.WD).replace('-','')}\"\n",
    "\n",
    "print(MODEL_FOLDER)\n",
    "print(KERNEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd909d43",
   "metadata": {
    "papermill": {
     "duration": 0.010524,
     "end_time": "2022-10-21T04:46:47.308030",
     "exception": false,
     "start_time": "2022-10-21T04:46:47.297506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Get kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5e8a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:50.415560Z",
     "iopub.status.busy": "2022-10-21T04:46:50.415286Z",
     "iopub.status.idle": "2022-10-21T04:46:50.457720Z",
     "shell.execute_reply": "2022-10-21T04:46:50.456777Z"
    },
    "papermill": {
     "duration": 0.057434,
     "end_time": "2022-10-21T04:46:50.459934",
     "exception": false,
     "start_time": "2022-10-21T04:46:50.402500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mskf = StratifiedGroupKFold(n_splits=CFG.n_splits, shuffle=True, random_state=121)\n",
    "fold_ids = []\n",
    "train['fold'] = 0\n",
    "\n",
    "for train_index, test_index in mskf.split(train,train['cancer'].values,train['patient_id'].values):\n",
    "    fold_ids.append(test_index)    \n",
    "\n",
    "for fld in range(CFG.n_splits):\n",
    "    valIx = fold_ids[fld]\n",
    "    train.loc[valIx,'fold']=fld "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f61d8",
   "metadata": {},
   "source": [
    "### Pre-processing function to cut pectoral muscles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8be858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_orient_mammogram(image):\n",
    "    left_nonzero = cv2.countNonZero(image[:, 0:int(image.shape[1]/2)])\n",
    "    right_nonzero = cv2.countNonZero(image[:, int(image.shape[1]/2):])\n",
    "    \n",
    "    if(left_nonzero < right_nonzero):\n",
    "        image = cv2.flip(image, 1)\n",
    "    return image\n",
    "\n",
    "def right_orient_mammogram_flag(image):\n",
    "    left_nonzero = cv2.countNonZero(image[:, 0:int(image.shape[1]/2)])\n",
    "    right_nonzero = cv2.countNonZero(image[:, int(image.shape[1]/2):])\n",
    "    \n",
    "    if(left_nonzero < right_nonzero):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def apply_canny(image):\n",
    "    canny_img = canny(image,2.25)\n",
    "    return sobel(canny_img)\n",
    "\n",
    "\n",
    "def get_hough_lines(canny_img):\n",
    "    h, theta, d = hough_line(canny_img)\n",
    "    lines = list()\n",
    "#     print('\\nAll hough lines')\n",
    "    for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n",
    "#         print(\"Angle: {:.2f}, Dist: {:.2f}\".format(np.degrees(angle), dist))\n",
    "        x1 = 0\n",
    "        y1 = (dist - x1 * np.cos(angle)) / np.sin(angle)\n",
    "        x2 = canny_img.shape[1]\n",
    "        y2 = (dist - x2 * np.cos(angle)) / np.sin(angle)\n",
    "        lines.append({\n",
    "            'dist': dist,\n",
    "            'angle': np.degrees(angle),\n",
    "            'point1': [x1, y1],\n",
    "            'point2': [x2, y2]\n",
    "        })\n",
    "    return lines\n",
    "\n",
    "def shortlist_lines(lines):\n",
    "    MIN_ANGLE = 1\n",
    "    MAX_ANGLE = 89\n",
    "    MIN_DIST  = 1\n",
    "    MAX_DIST  = 384\n",
    "    \n",
    "    shortlisted_lines = [x for x in lines if \n",
    "                          (x['dist']>=MIN_DIST) &\n",
    "                          (x['dist']<=MAX_DIST) &\n",
    "                          (x['angle']>=MIN_ANGLE) &\n",
    "                          (x['angle']<=MAX_ANGLE)\n",
    "                        ]\n",
    "        \n",
    "    return shortlisted_lines\n",
    "\n",
    "\n",
    "def remove_pectoral(shortlisted_lines):\n",
    "    shortlisted_lines.sort(key = lambda x: x['dist'])\n",
    "    pectoral_line = shortlisted_lines[0]\n",
    "    d = pectoral_line['dist']\n",
    "    theta = np.radians(pectoral_line['angle'])\n",
    "    x_intercept = d/np.cos(theta)\n",
    "    y_intercept = d/np.sin(theta)\n",
    "    return polygon([0, 0, y_intercept], [0, x_intercept, 0])\n",
    "\n",
    "def removePre_proc(image):\n",
    "    canny_image = apply_canny(image)\n",
    "    lines = get_hough_lines(canny_image)\n",
    "    shortlisted_lines = shortlist_lines(lines)\n",
    "    rr, cc = remove_pectoral(shortlisted_lines)\n",
    "    image[rr, cc] = 114\n",
    "    return image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4257f342",
   "metadata": {},
   "source": [
    "### Pre-processing function to crop black area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_blackarea(d):\n",
    "    X = cv2.imread(os.path.join(image_dir,f'{d.patient_id}_{d.image_id}.png'))\n",
    "    X = X[5:-5, 5:-5]\n",
    "    \n",
    "    # regions of non-empty pixels\n",
    "    output= cv2.connectedComponentsWithStats((X > 20).astype(np.uint8)[:, :, 0], 8, cv2.CV_32S)\n",
    "\n",
    "    stats = output[2]\n",
    "\n",
    "    # finding max area which always corresponds to the breast data. \n",
    "    idx = stats[1:, 4].argmax() + 1\n",
    "    x1, y1, w, h = stats[idx][:4]\n",
    "    x2 = x1 + w\n",
    "    y2 = y1 + h\n",
    "    \n",
    "    # cutting out the breast data\n",
    "    X_fit = X[y1: y2, x1: x2]\n",
    "    return X_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb2b79",
   "metadata": {
    "papermill": {
     "duration": 0.011456,
     "end_time": "2022-10-21T04:46:50.483973",
     "exception": false,
     "start_time": "2022-10-21T04:46:50.472517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36482fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(d):\n",
    "    image = cv2.imread(os.path.join(image_dir,f'{d.patient_id}_{d.image_id}.png'),cv2.IMREAD_GRAYSCALE)\n",
    "    return image\n",
    "\n",
    "def cropFn(d):\n",
    "    X = cv2.imread(os.path.join(image_dir,f'{d.patient_id}_{d.image_id}.png'),cv2.IMREAD_GRAYSCALE)\n",
    "    flag = right_orient_mammogram_flag(X)\n",
    "    X = crop_blackarea(X)\n",
    "    if flag:\n",
    "        X = cv2.flip(X, 1)\n",
    "    return X\n",
    "\n",
    "def procImg(image):\n",
    "    image = np.expand_dims(image, -1)\n",
    "    mean = np.array([0., 0., 0.]).reshape(3, 1, 1)\n",
    "    std = np.array([1., 1., 1.]).reshape(3, 1, 1)\n",
    "    image /= 255.0\n",
    "    image = np.ascontiguousarray(image.transpose((2, 0, 1)))\n",
    "    image = (image - mean)/std\n",
    "    image = torch.from_numpy(image).float()\n",
    "    return image\n",
    "\n",
    "class RsnaDataset(Dataset):\n",
    "    def __init__(self, df, augs=None,mode='train',cutpectocal = True):\n",
    "        self.length = len(df)\n",
    "        self.df = df\n",
    "        self.augs = augs\n",
    "        self.mode = mode\n",
    "        self.cutpectocal = cutpectocal\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        d = self.df.iloc[index]\n",
    "        patient_id = d.patient_id\n",
    "        image = cropFn(d)\n",
    "        if self.cutpectocal:\n",
    "            try:\n",
    "                image = removePre_proc(image)\n",
    "            except:\n",
    "                image = image\n",
    "        \n",
    "        if self.augs is not None:\n",
    "            image = self.augs(image=image)['image'].astype(float)\n",
    "        image = procImg(image)\n",
    "        cancer = torch.tensor(d.cancer).float()\n",
    "        if self.mode=='test':\n",
    "            return image,patient_id\n",
    "        return image,cancer,patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101207aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:51.351557Z",
     "iopub.status.busy": "2022-10-21T04:46:51.351216Z",
     "iopub.status.idle": "2022-10-21T04:46:51.356377Z",
     "shell.execute_reply": "2022-10-21T04:46:51.355263Z"
    },
    "papermill": {
     "duration": 0.025285,
     "end_time": "2022-10-21T04:46:51.358947",
     "exception": false,
     "start_time": "2022-10-21T04:46:51.333662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"\n",
    "    Handles PyTorch x Numpy seeding issues.\n",
    "    Args:\n",
    "        worker_id (int): Id of the worker.\n",
    "    \"\"\"\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b59ef",
   "metadata": {},
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ddfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_AUG = A.Compose([\n",
    "    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.03, rotate_limit=15, p=0.5, border_mode=0),\n",
    "    A.OneOf([A.HorizontalFlip(p = 0.5),\n",
    "    A.VerticalFlip(p = 0.5)],p=0.5),    \n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.OneOf(\n",
    "        transforms=[\n",
    "           A.OpticalDistortion(p=0.3),\n",
    "            A.GridDistortion(p=0.1),\n",
    "            A.PiecewiseAffine(p=0.3)],p=0.2),\n",
    "    A.Affine(translate_percent=0.1, rotate=30, shear=0, scale=[0.8,1.2], p= 0.5),\n",
    "    A.CoarseDropout(max_holes=8, max_height= 5, max_width= 5, p=0.5),\n",
    "    A.Cutout(num_holes = 8,max_h_size = 5, max_w_size = 5, p=0.7),\n",
    "    A.Resize(CFG.SZ[0],CFG.SZ[1]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "VALID_AUG = A.Compose([\n",
    "    A.Resize(CFG.SZ[0],CFG.SZ[1]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf59ae",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4410391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_show = RsnaDataset(train, augs=TRAIN_AUG, mode='train')\n",
    "loader_show = torch.utils.data.DataLoader(dataset_show, batch_size=6)\n",
    "img,target,_ = next(iter(loader_show))\n",
    "\n",
    "grid = torchvision.utils.make_grid(img, normalize=True, padding=2)\n",
    "grid = grid.permute(1, 2, 0)\n",
    "show_image(grid, figsize=(15,8),title=[x for x in target.numpy()]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f9823",
   "metadata": {
    "papermill": {
     "duration": 0.012058,
     "end_time": "2022-10-21T04:46:51.383502",
     "exception": false,
     "start_time": "2022-10-21T04:46:51.371444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20034eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rsna_classification_model(model_name, pretrained=True, **kwargs):\n",
    "    model = timm.create_model(CFG.MODEL, pretrained=pretrained,num_classes=1,in_chans=3, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e031126",
   "metadata": {},
   "source": [
    "### QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41add6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:51.748231Z",
     "iopub.status.busy": "2022-10-21T04:46:51.747517Z",
     "iopub.status.idle": "2022-10-21T04:46:51.959456Z",
     "shell.execute_reply": "2022-10-21T04:46:51.958430Z"
    },
    "papermill": {
     "duration": 0.227045,
     "end_time": "2022-10-21T04:46:51.962222",
     "exception": false,
     "start_time": "2022-10-21T04:46:51.735177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl = DataLoader(RsnaDataset(train, augs=TRAIN_AUG, mode='train'),\n",
    "                          batch_size=2,\n",
    "                          shuffle=True,\n",
    "                          num_workers=8,\n",
    "                          drop_last=True,\n",
    "                          worker_init_fn=worker_init_fn)\n",
    "\n",
    "a,b,_ = next(iter(dl))\n",
    "a.shape,b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3e892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:51.987500Z",
     "iopub.status.busy": "2022-10-21T04:46:51.987165Z",
     "iopub.status.idle": "2022-10-21T04:46:58.618975Z",
     "shell.execute_reply": "2022-10-21T04:46:58.616805Z"
    },
    "papermill": {
     "duration": 6.647161,
     "end_time": "2022-10-21T04:46:58.621465",
     "exception": false,
     "start_time": "2022-10-21T04:46:51.974304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = get_rsna_classification_model(CFG.MODEL)\n",
    "out = m(a)\n",
    "print(out, out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fff2ad",
   "metadata": {
    "papermill": {
     "duration": 0.013027,
     "end_time": "2022-10-21T04:46:58.648053",
     "exception": false,
     "start_time": "2022-10-21T04:46:58.635026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train & Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597af09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:58.675824Z",
     "iopub.status.busy": "2022-10-21T04:46:58.674778Z",
     "iopub.status.idle": "2022-10-21T04:46:58.683272Z",
     "shell.execute_reply": "2022-10-21T04:46:58.682071Z"
    },
    "papermill": {
     "duration": 0.025267,
     "end_time": "2022-10-21T04:46:58.685455",
     "exception": false,
     "start_time": "2022-10-21T04:46:58.660188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pfbeta(labels, preds, beta=1,clip=True):\n",
    "    if clip:\n",
    "        preds = preds.clip(0, 1)\n",
    "    y_true_count = labels.sum()\n",
    "    ctp = preds[labels==1].sum()\n",
    "    cfp = preds[labels==0].sum()\n",
    "    beta_squared = beta * beta\n",
    "    c_precision = ctp / (ctp + cfp)\n",
    "    c_recall = ctp / y_true_count\n",
    "    if (c_precision > 0 and c_recall > 0):\n",
    "        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n",
    "        return result\n",
    "    else:\n",
    "        return torch.tensor(0.0)\n",
    "    \n",
    "def pfbeta_thresh(labels, preds, beta=1):\n",
    "    preds = preds>0.2\n",
    "    y_true_count = labels.sum()\n",
    "    ctp = preds[labels==1].sum()\n",
    "    cfp = preds[labels==0].sum()\n",
    "    beta_squared = beta * beta\n",
    "    c_precision = ctp / (ctp + cfp)\n",
    "    c_recall = ctp / y_true_count\n",
    "    if (c_precision > 0 and c_recall > 0):\n",
    "        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n",
    "        return result\n",
    "    else:\n",
    "        return torch.tensor(0.0)\n",
    "    \n",
    "def optimal_f1(labels, predictions):\n",
    "    labels = labels.cpu().numpy()\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    thres = np.linspace(0, 1, 100)\n",
    "    f1s = [pfbeta(labels, predictions > thr,clip=False) for thr in thres]\n",
    "    idx = np.argmax(f1s)\n",
    "    return f1s[idx], thres[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c498a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: Iterable,\n",
    "    loss_fn: Callable,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    lr_scheduler: torch.optim.lr_scheduler._LRScheduler = None,\n",
    "    mixup_fn: Callable = None,\n",
    "    grad_scaler: torch.cuda.amp.GradScaler = None,\n",
    "    mbar: master_bar = None,\n",
    "):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses_m = utils.AverageMeter()\n",
    "\n",
    "    pbar = progress_bar(loader, parent=mbar, leave=False)\n",
    "    pbar.update(0)\n",
    "\n",
    "    for batch_idx, (input, target,_) in enumerate(loader):\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            output = model(input)\n",
    "            loss = loss_fn(output, target.reshape(-1,1))\n",
    "            \n",
    "        losses_m.update(loss.item(), input.size(0))\n",
    "\n",
    "        grad_scaler.scale(loss).backward()\n",
    "        grad_scaler.step(optimizer)\n",
    "        grad_scaler.update()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        pbar.update(batch_idx + 1)\n",
    "        pbar.comment = f\"{losses_m.avg:.4f}\"\n",
    "\n",
    "    pbar.on_iter_end()\n",
    "    return OrderedDict([(\"loss\", losses_m.avg)])\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def validate(model: nn.Module, loader: Iterable, loss_fn: Callable, mbar: master_bar):\n",
    "    model.eval()\n",
    "\n",
    "    metric_m = utils.AverageMeter()\n",
    "    metric_m_thresh = utils.AverageMeter()\n",
    "    auc_m = utils.AverageMeter()\n",
    "    losses_m = utils.AverageMeter()\n",
    "\n",
    "    pbar = progress_bar(loader, parent=mbar, leave=False)\n",
    "    pbar.update(0)\n",
    "\n",
    "    for batch_idx, (input, target,_) in enumerate(loader):\n",
    "        \n",
    "        input, target = input.cuda(), target.cuda()\n",
    "        output = torch.round(model(input))\n",
    "\n",
    "        loss = loss_fn(output, target.reshape(-1,1)).item()\n",
    "        losses_m.update(loss, input.size(0))\n",
    "        \n",
    "        output = F.sigmoid(output)\n",
    "        metric = pfbeta(target,output).item()\n",
    "        metric_thresh,_ = optimal_f1(target, output)# pfbeta_thresh(target,output).item()\n",
    "        metric_m.update(metric, output.size(0))\n",
    "        metric_m_thresh.update(metric_thresh.item(), output.size(0))\n",
    "        pbar.update(batch_idx + 1)\n",
    "\n",
    "    pbar.on_iter_end()\n",
    "    return OrderedDict([(\"loss\", losses_m.avg), (\"metric\", metric_m.avg),(\"metric_thresh\", metric_m_thresh.avg)])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddd2ddb7",
   "metadata": {},
   "source": [
    "### Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalanceSampler(Sampler):\n",
    "    \n",
    "    def __init__(self, dataset, ratio=8):\n",
    "        self.r = ratio-1\n",
    "        self.dataset = dataset\n",
    "        self.pos_index = np.where(dataset.df.cancer>0)[0]\n",
    "        self.neg_index = np.where(dataset.df.cancer==0)[0]\n",
    "\n",
    "        self.length = self.r*int(np.floor(len(self.neg_index)/self.r))\n",
    "\n",
    "    def __iter__(self):\n",
    "        pos_index = self.pos_index.copy()\n",
    "        neg_index = self.neg_index.copy()\n",
    "        np.random.shuffle(pos_index)\n",
    "        np.random.shuffle(neg_index)\n",
    "\n",
    "        neg_index = neg_index[:self.length].reshape(-1,self.r)\n",
    "        pos_index = np.random.choice(pos_index, self.length//self.r).reshape(-1,1)\n",
    "\n",
    "        index = np.concatenate([pos_index,neg_index],-1).reshape(-1)\n",
    "        return iter(index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ee4a01",
   "metadata": {},
   "source": [
    "### Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60917654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(fold):\n",
    "    \n",
    "    with IPyExperimentsPytorch(exp_enable=False, cl_set_seed=42, cl_compact=True):\n",
    "        print()\n",
    "        print(\"*\" * 100)\n",
    "        print(f\"Training fold {fold}\")\n",
    "        print(\"*\" * 100)\n",
    "\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "      \n",
    "        dataset_train = RsnaDataset(train.query(\"fold!=@fold\").reset_index(drop=True), augs=TRAIN_AUG, mode=\"train\")\n",
    "        dataset_valid = RsnaDataset(train.query(\"fold==@fold\").reset_index(drop=True), augs=VALID_AUG, mode=\"valid\")\n",
    "\n",
    "        print(f\"TRAIN: {len(dataset_train)} | VALID: {len(dataset_valid)}\")\n",
    "\n",
    "        loader_train = torch.utils.data.DataLoader(dataset_train, \n",
    "                                                   CFG.BS, \n",
    "                                                   num_workers=8, \n",
    "                                                   drop_last=True,\n",
    "                                                  pin_memory=True)#,\n",
    "        loader_valid = torch.utils.data.DataLoader(dataset_valid, CFG.BS * 2, num_workers=8, shuffle=False)\n",
    "\n",
    "        model = get_rsna_classification_model(CFG.MODEL, pretrained=True)#, drop_path_rate=0.15)\n",
    "        model.cuda()\n",
    "        optimizer = create_optimizer_v2(model, \"lookahead_RAdam\", lr=CFG.LR)\n",
    "\n",
    "        num_train_steps = len(loader_train) * CFG.EP\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_train_steps)\n",
    "\n",
    "        train_loss_fn = nn.BCEWithLogitsLoss()\n",
    "        valid_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        grad_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        print(f\"Scheduled epochs: {CFG.EP}\")\n",
    "\n",
    "        mbar = master_bar(list(range(CFG.EP)))\n",
    "        best_epoch, best_metric = 0, 100\n",
    "        metric_names = [\"epoch\", \"train_loss\", \"valid_loss\", \"metric\",\"metric_thresh\", \"time\"]\n",
    "        mbar.write([f\"{l:.6f}\" if isinstance(l, float) else str(l) for l in metric_names], table=True)\n",
    "\n",
    "        for epoch in range(CFG.EP):\n",
    "            start_time = time.time()\n",
    "            mbar.update(epoch)\n",
    "\n",
    "            train_metrics = train_one_epoch(\n",
    "                model, loader_train, train_loss_fn, optimizer,\n",
    "                lr_scheduler=lr_scheduler, mixup_fn=None, grad_scaler=grad_scaler, mbar=mbar)\n",
    "\n",
    "            valid_metrics = validate(model, loader_valid, valid_loss_fn, mbar=mbar)\n",
    "            \n",
    "            elapsed = format_time(time.time() - start_time)\n",
    "            epoch_log = [epoch,train_metrics[\"loss\"], valid_metrics[\"loss\"], valid_metrics[\"metric\"],\n",
    "                         valid_metrics[\"metric_thresh\"], elapsed]\n",
    "            mbar.write([f\"{l:.6f}\" if isinstance(l, float) else str(l) for l in epoch_log], table=True)\n",
    "\n",
    "            if 1:\n",
    "                best_epoch, best_metric = epoch, valid_metrics[\"loss\"]\n",
    "                path = Path(f'{MODEL_FOLDER}/fold_{fold}')\n",
    "                os.makedirs(path,exist_ok=True)\n",
    "                dirpath = path / (KERNEL_TYPE + f\"_Epoch_{epoch}_fold_{fold}.pth\")\n",
    "                torch.save(model.state_dict(), dirpath)\n",
    "                    \n",
    "        mbar.on_iter_end()\n",
    "        print(\"*** Best metric: {0} (epoch {1})\".format(best_metric, best_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d8727c",
   "metadata": {},
   "source": [
    "### Train 4 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc7877d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for fold_idx in [0,1,2,3]:\n",
    "    training_loop(fold_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb2bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dc35c69",
   "metadata": {},
   "source": [
    "### OOF Generation and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6788d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_oof(fold):\n",
    "   \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dataset_valid = RsnaDataset(train.query(\"fold==@fold\").reset_index(drop=True), augs=VALID_AUG, mode=\"valid\")\n",
    "    print(f\"VALID: {len(dataset_valid)}\")\n",
    "\n",
    "    loader_valid = torch.utils.data.DataLoader(dataset_valid, CFG.BS * 2, num_workers=8, shuffle=False)\n",
    "    model = get_rsna_classification_model(CFG.MODEL, pretrained=False)\n",
    "    model.load_state_dict(torch.load(f'{MODEL_FOLDER}/fold_{fold}/{KERNEL_TYPE}_Epoch_{CFG.EP-1}_fold_{fold}.pth'))\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "\n",
    "    preds = []\n",
    "    imageids = []\n",
    "\n",
    "    for input,label,patient_id in tqdm(loader_valid, dynamic_ncols=True, desc=\"OOF Generation\"):\n",
    "        pred = []\n",
    "        with torch.cuda.amp.autocast(), torch.no_grad():\n",
    "            input = input.cuda()\n",
    "            pred.append(F.sigmoid(model(input)))\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        preds.append(torch.concat(pred).data.cpu().numpy())\n",
    "    return np.concatenate(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7efbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [0,1,2,3]\n",
    "oof = np.zeros((len(train)))\n",
    "for k in tqdm(folds):\n",
    "    oof_fold,ix = gen_oof(k)\n",
    "    print(oof_fold.min(),oof_fold.max())\n",
    "    oof[ix] += oof_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c476ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_f1_numpy(oof,fold):\n",
    "    labels = train.loc[train['fold'].isin(fold)].reset_index(drop=True)['cancer'].values\n",
    "    oof = oof[train.loc[train['fold'].isin(fold)].index]\n",
    "    thres = np.linspace(0, 1, 100)\n",
    "    f1s = [pfbeta(labels, oof > thr,clip=False) for thr in thres]\n",
    "    idx = np.argmax(f1s)\n",
    "    return f1s[idx], thres[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scr, thresh = optimal_f1_numpy(oof,folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c2681",
   "metadata": {},
   "outputs": [],
   "source": [
    "scr,thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb57bf2",
   "metadata": {
    "id": "T0Z5tB5f8obu",
    "papermill": {
     "duration": 0.018419,
     "end_time": "2022-10-21T04:58:56.268413",
     "exception": false,
     "start_time": "2022-10-21T04:58:56.249994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Fin "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 771.032802,
   "end_time": "2022-10-21T04:58:58.627815",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-21T04:46:07.595013",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
